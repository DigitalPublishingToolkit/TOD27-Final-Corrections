---
Pr-id: MoneyLab
P-id: INC Reader
A-id: 10
Type: article
Book-type: anthology
Anthology item: article
Item-id: unique no.
Article-title: title of the article
Article-status: accepted
Author: name(s) of author(s)
Author-email:   corresponding address
Author-bio:  about the author
Abstract:   short description of the article (100 words)
Keywords:   50 keywords for search and indexing
Rights: CC BY-NC 4.0
...


# 3. Building the Videoblogging Infrastructure: A Brief History.

The early development of the videoblogging community in many ways maps
directly onto the growth of online video technologies on the internet.
In this chapter I want to critically engage with videoblogging as a
technical platform. I do this in part by looking at archived
technologies, discourses and recordings of events, combined with an
exploration of the research data gathered during the empirical study
conducted over the course of my ethnography. As such, this chapter has
two main functions. The first is concerned with mapping the development
of a constellation of technologies. The second is concerned with how the
videobloggers articulate their technical practices, which include the
kinds of technologies they use, how they express their highly technical
digital skills, camera skills, and how they organise around and through
their social networks. Running through the analysis are the technical
contours of the short-form digital film, usually under ten minutes in
length, due mainly to technical limitations, narrative practices within
videoblogging, as well as social norms and practice. This informs part
of the self-description, or subject position, occupied by the
videoblogger. This process of identity-making can be seen in relation to
what we might consider a nascent form of database informed narrative,
using digital tools to cut and paste film in innovative ways. This
editing process opens up new and radical forms of video-reflexivity in
the presentation of self. This is combined with reticular video-sharing
fascilitated by bespoke tools and blogging platforms to distribute this
through a shared community of practice.

There is considerable literature on the emergence of digital culture,
life on the screen, communities and lived experiences online,[^04chapter3_1] yet it
is only in recent years that focus has started shifting towards a closer
analysis of the material structures of the web.[^04chapter3_2] The advent of
software studies and infrastructure studies, network politics, tactical
media and political economic studies of code and software, has meant
that more attention is given to the structures that facilitate and shape
digital media. The study of computational systems is made difficult by
the fact that researchers often have limited or no access to what lies
beneath the interface itself,[^04chapter3_3] and indeed in my own work I have had
to acquaint myself with unfamiliar technical details which are often
obscure, difficult to understand and unfriendly for non-technical
researchers. With this in mind, I introduce some of the major
technologies underlying videoblogging and briefly describe their
emergence and development. The aim is to contextualise these technical
systems, but also to provide a map of the continuities and
discontinuities that videoblogging, and particularly its technical side,
have in relation to internet technologies.

In this chapter, I move rapidly through the history of a number of
technical and social systems and due to limitations of space, I cannot
hope to do them all justice here. Nonetheless, the aim is to provide some
sense of the major events, technologies and movements that are important
for the light they cast on understanding the rise of videoblogging,
which is, of course, the focus of this book.

First, I want to spend a small amount of time thinking about the
internet as a now well-known a global computer network. Often described
as a network of networks, the internet was developed by Darpa in the
1960s. Its quasi-military origins show how ‘military concerns and goals
were built into the Internet technology… favour\[ing\] military values,
such as survivability, flexibility, and high performance, over
commercial goals, such as low cost, simplicity or consumer appeal’.[^04chapter3_4]
But much of the development of the DARPAnet was technical as well as
militaristic, driven by engineers and mathematicians who were invested
in the network through a love of programming, not a concern for military
tactics. Decisions made early on to implement things like packet
switching and networked computers were seen as technical problems, often
divorced from their social context as a way to increase computing time
and increase efficiency across the network.

But the internet also opened up, often inadvertently, new possibilities
through its agnostic approach to centralisation, verification and
hierarchy. That is not to say there are no hierarchies manifested on the
internet, indeed that is patently untrue. Rather, earlier decisions on
the technical structure allowed multiple points of communication,
shifting to a model of data transfer and a paradigm of knowledge that
was networked and distributed. This later created the ideal conditions
for the spread of grass roots, viral media forms. It remains a curious
historical artifact that the cold war should produce a counter-power in
the form of a reticular system that the internet makes possible. Of
course, this is the foundation on which videoblogging and other social
media were built.

The origins of the ideas that informed the internet might be traced back
as far as 1938, with H.G Wells’ publication of *World Brain*, a concept
that conceived of ‘a complete planetary memory for all mankind’. Wells’
ideas re-emerged in the writings of Vannevar Bush, whose *As We May
Think* from 1945 described a collective memory machine for information
storage and retrieval called the *memex*. The traditional narrative
about the origins of the internet tends to describe the ‘demonstration
of 4-node ARPANET network in 1969’ as the ‘epoch-making’ moment.
Campbell-Kelly and Garcia-Swartz argue that ‘when the Internet took off
in the early 1990s the world was covered by thousands of isolated
networks and the integration of these networks into a global entity was
likely to happen, whether ARPANET existed or not’ due to the fact that
linking up these systems was an obvious inventive step in the
development of networking technology.[^04chapter3_5] But we have to keep in mind
the difference between the internet and the World Wide Web that was
built upon it and which was inspired by these previous ideas.

The World Wide Web didn’t emerge out of the ARPA research community
itself, but from a separate group of computer scientists working at the
European Organization for Nuclear Research, CERN, amongst them Tim
Berners-Lee and Robert Cailliau. Berners-Lee developed the world wide
web in response to the increasing difficulty of sharing information
between scientists at dispersed universities and other institutions
across the world. The World Wide Web also owes some debt to the work on
hypertext developed by Ted Nelson, whose manifesto *Computer Lib* (1974)
partly influenced Berners-Lee.[^04chapter3_6] What was unique about the web as
conceived by Berners-Lee, was that it did not require a directory of any
kind, be it local or global. As Berners-Lee explains;

> Given the go-ahead to experiment… I wrote in 1990 a program called
> ‘WorldWideWeb’, a point and click hypertext editor which ran on the
> “NeXT” machine. This, together with the first Web server, I released
> to the High Energy Physics community at first, and to the hypertext
> and NeXT communities in the summer of 1991.

The ‘specifications of UDIs (now URIs), HyperText Markup Language (HTML)
and HyperText Transfer Protocol (HTTP) \[were\] published on the first
server in order to promote wide adoption and discussion.’[^04chapter3_7] Needless
to say, their simplicity and ease of implementation meant that they were
widely used, and usage accelerated over time.

It is also important to remember that sociality was happening across
computer networks long before the development of the web. In fact, the
first Bulletin Board System (BBS) went online in 1978 and grew
increasingly popular as functionality improved. Initially, only one user
could be online at any one time, but by 1994 it became possible for
users of bulletin boards to connect to one another through low-speed
telephone networks’.[^04chapter3_8] In 1985, Larry Brilliant and Stewart Brand
started the Whole Earth ’Lectronic Link (the WELL), which went on to
become one of the most prolific, and certainly one of the most
influential online communities at the time.[^04chapter3_9] These early technical
platforms that inculcate a sense of belonging, and hence a sense of
community, soon gave rise to the emergence of community-formation as an
explicit design goal. Of course we are familiar with this logic, which
today is incorporated into platforms, but in these early days community
often emerged organically.

By October 24th 1995, the formal definition of the term ‘the internet’
was unanimously agreed by the Federal Networking Council (FNC). The
resolution states that the Federal Networking Council (FNC) agreed to
define the term ‘Internet’ as ‘the global information system that – (i)
is logically linked together by a globally unique address space based on
the Internet Protocol (IP) or its subsequent extensions/follow-ons; (ii)
is able to support communications using the Transmission Control
Protocol/Internet Protocol (TCP/IP) suite or its subsequent
extensions/follow-ons, and/or other IP-compatible protocols; and (iii)
provides, uses or makes accessible, either publicly or privately, high
level services layered on the communications and related infrastructure
described herein.’[^04chapter3_10] In 1995, the number of commercial users also
overtook the number of research and academic users.

Conflicting ideas about the internet have circulated since its
emergence. As previously mentioned, John Perry Barlow’s *Declaration of
the Independence of Cyberspace* demanded autonomy from governments and
nation states.[^04chapter3_11] The declaration was part of the writings of a
generation of thinkers influenced by the revolutionary rhetoric
associated with the early web, drawn from, among others, William
Gibson’s *Neuromancer* (from 1984) and government discourse on the
‘information superhighway’. A close reading of Barlow’s text, however,
reveals ‘a wealth of contradictions and misdirection: newness is rooted
in history; revolution is effected by commercial transaction; and
liberal democracy becomes libertarianism’.[^04chapter3_12] Nevertheless, the
bodiless, immaterial world of distributed identities Barlow describes
can be seen reflected in early writings on behaviour and communities
online. Writers such as Sherry Turkle and Howard Rheingold both describe
user practices and community bonds that are somehow intensified through
digital technology. This utopianism is reflected through a discourse
describing ‘diffused networks \[which\] *equalize* social practices and
values evolved in and around them’ and describe ‘*all* virtual social
practices \[as\] equalised in the sense of being “more equal than the
real world”’.[^04chapter3_13] It is interesting to note the degree to which
Barlow’s writing contributed to a conception of cyberspace and its users
that emphasised immateriality and virtuality above materiality. We might
note this moment as a significant marker for the emergence of the
dichotomy within technical systems of the tension between the individual
and community. This remains in place today in most technical systems,
and of course reflects a wider contradiction manifest in liberal
democratic systems within capitalism.

These early systems had a strong feedback loop between community and
network, with the network here understood as including the developers of
the platform itself. As such, ‘Web 2.0 platforms are not simply about
facilitating user-produced content and carrying content across networks
to large audiences or ‘end-users’; rather, they are primarily concerned
with establishing the technocultural conditions within which users can
produce content and can be re-channelled through techno-commercial
networks and channels.’[^04chapter3_14] Indeed, a software platform has to work to
inculcate a sense of community in users, understood here as a form of
sociality, and into their technical processes. Or to put it another way,
it is when the network and the community are brought together that a
socially-oriented platform can emerge. Langlois et al put it aptly when
they write, ‘the ontogenesis of Web 2.0 is about the creation of
inhabitable worlds within which users can exist and extend themselves
according to specific technocultural logics’. Once a certain logic of
sociality within technical systems had been identified, this notion of
community was quickly incorporated into the development of online
network platforms. In many ways, Web 2.0 was the first codification of
this logic online, although of course this exploitation of the social
inclinations of human beings had been used throughout the twentieth
century in a number of marketing and PR processes for industrial
production and consumption.

It is now common for technical platforms, when they are launched
commercially, to alienate the original early community surrounding its
technical development, and in many cases to offer little monetary
rewards to the very people who were so instrumental in its early
success. Examples abound of these ways of exploiting early adopter
communities, Apple, for example, was heavily reliant on its early
adopter community before it become successful.[^04chapter3_15] Equally, we can
consider the examples of Flickr, which originally had a means for the
community to take a part in its governance. This practice was also
followed by Facebook and Instagram, which, in the case of Facebook,
later proposed to amend and remove this ‘community’ from the company
ordinances in December 2012 when they began an IPO process, that is when
they realised that community stood in the way of profits.

I now want to turn from this broad overview to think about the more
particular case of technologies that were key to the development of
videoblogging. For example, one of these is the video codec format
technologies which were crucial for allowing the encoding (‘co’) and
decoding (‘dec’) video. I want to spend some time talking about codecs
mainly because they are key technologies – but also because they were
highly unstable, constantly shifting, except at the time that
videoblogging emerged. In some sense, due to a number of different
external factors, codecs stabilised, which enabled users to get a grip
on the technologies and utilise them to produce creative work.

The technical conditions for online video were represented by codecs and
compression algorithms that were changing digital video. A codec is a
device or computer program responsible for encoding or decoding a
digital stream and a standard. It is a compression format – a way of
storing data – and an implementation of a program that can read and
write compressed files. After being compressed, files only retain some
of the data from the original file (this is called a lossy format), so
in some sense the codec could be considered a ‘translator’ that makes
decisions about which data is included in the compressed file – so
called lossy compression. To store large files on computers, or to
transmit them across networks, requires that they are ‘compressed’. This
means that through clever mathematical equations, a digital file can be
reduced in size, sometimes dramatically, and therefore assist in the
sharing and transfer of files. Perhaps the most famous version of
compression is that of MP3, which was able to reduce a file in size by
more than half. This allowed music files to be fitted on a number of
devices, but also shared widely on the internet.[^04chapter3_16] Similarly, for
video, compression algorithms made video on the internet (but also DVDs,
BluRay and 4K video compression) possible. It goes without saying that
video compression was a key technology that laid the foundations for
videoblogging. But using video compression codecs is not just technical,
it is also a social practice. There has to be some social agreement on
which practices are reflected in the technical standards used – in order
to create, use view and distribute the community work and ideas.

Ursula Franklin suggests that thinking about technology as practice
‘links technology directly to culture, because culture, after all, is a
set of socially accepted practices and values’. Moreover, Franklin
suggests that ‘well laid upon practices also define the practitioners as
a group of people who have something in common’. Further, she argues
that ‘the experience of common practice is one of the ways in which
people define themselves as groups and set themselves apart from
others’.[^04chapter3_17] In terms of the videobloggers, this *setting themselves
apart* is perhaps most clearly seen in their attitudes towards
technology and video platforms, and one of the issues I want to spend
some time on to show how video technologies and platforms developed in a
crucial time between 2004 and 2007.

Today, there are a plethora of video codecs. Here, though, I wish to
highlight QuickTime in particular. QuickTime was one of the fundamental
technologies that formed part of the videoblogging practice. Apart from
a very small number of users who relied on Windows Media Player, the
majority of the independent videobloggers I interviewed relied on
QuickTime (both the application and the codec) in some way through their
videoblogging practice.[^04chapter3_18] As Cubitt argues, ‘there is no internet
without the standardisation of internet protocols; and there is no
exchange of moving pictures without standardisation of the codecs on
which the various proprietary players can function’.[^04chapter3_19] I highlight
QuickTime because it was such an important codec for the videobloggers
to know and understand, and because, as it turns out, the
development-cycle of QuickTime was significant to the videobloggers.
QuickTime was also the first consumer-based video handler that actually
worked, both as video support and as a shared platform amongst a large
group of users. Manovich argues that the ‘introduction of QuickTime in
1991 can be compared to the introduction of the Kinetoscope in 1892:
Both were used to present short loops, both featured images
approximately two by three inches in size, both called for private
viewing rather than collective exhibition.’[^04chapter3_20] Manovich shows how the
QuickTime and the Kinetoscope even appear to play a similar role in the
cultural sense;

> If in the early 1890s the public patronized Kinetoscope parlours where
> peep-hole machines presented them with the latest marvel – tiny,
> moving photographs arranged in short loops – exactly a hundred years
> later, computer users were equally fascinated with tiny QuickTime
> movies that turned a computer into a film projector, however
> imperfect.

QuickTime was an extensible software framework that abstracted many of
the complexities of multimedia formats. It not only supported the
playback of video but allowed encodings of video and transcoding to
other formats. The native video format for QuickTime was called
QuickTime File Format, which was a ‘container file’ that stored
different types of data, such as audio, video, texts or effects. Because
QuickTime contained an abstraction of the underlying formats, it could
support abstract references and edit lists – this made QuickTime ideal
for editing video. Its abstraction affordance meant that other formats
could be ‘plugged in’ to the framework and it could therefore handle
other popular formats like Asf, DivX etc. Indeed, in many ways,
QuickTime was the ‘killer app’ for videoblogging.

QuickTime was originally designed by Bruce Leak and was first shown to
the public at the World Wide Developer Conference in May 1991. During
Apple’s onstage presentation, QuickTime was displayed playing Apple’s
iconic 1984 advert playing directly off the computer on the stage. As
has become usual with Apple’s big launch presentations, the event was a
huge success and QuickTime was considered an astounding technical
breakthrough. The first generation of QuickTime (version 1.0) displayed
an aspect ratio of 320 x 240 pixels, and had a frame rate of 15 frames
per seconds, fairly primitive to us today, but a real technical
achievement at the time.

The next year, 1992, Apple launched QuickTime 1.5, which added the
Cinepac codec and vector-quantization. Cinepac was a lossy video codec
that had previously been used in, amongst others, the Atari Jaguar. This
allowed for more compact video compression. The 320 x 240 ratio
remained, but QuickTime now supported 30 frames per second. Apple also
added text tracks, and released their first Windows compatible version
of QuickTime (1.0 for Windows). This version included Cinepac and INDIO
(from Intel). In February 1994, Apple launched QuickTime 2.0, which
supported the addition of music tracks in addition to the already
supported video and text. With this, QuickTime was becoming a fully
integrated multimedia format. In the same year, Microsoft launched their
competitor Video for Windows (version 1.0), using Microsoft’s own RLE
and Video Codecs, but these were woeful in comparison, having few of the
technical breakthroughs of QuickTime.

QuickTime 2.5 was launched in 1995, and supported sprite tracks (which
allowed the use of animation to be superimposed over the video) and an
early version of Virtual Reality (VR). In the same year, Microsoft
launched Windows 95 which came with the Direct X codec – an important
competitor technology. The languages Java and Javascript were also
introduced in 1995. In 1997, QuickTime MPEG was launched, which
basically allowed and supported the playback of the MPEG codec. This is
significant because the MPEG format was an important industry standard.
1998 saw Apple launching QuickTime 3.0, which added the ability for
QuickTime to understand GIFs, JPEGs and TIFFs. Perhaps more importantly,
QuickTime 3.0 allowed the user to output video directly to Firewire,
cutting down export time dramatically. QuickTime 3.0 also included
support for the Sorenson video codec, which meant QuickTime could now
support fully professional codecs.

In June 1999, Apple launched both QuickTime 4.0 for Mac and QuickTime
4.0 for Windows. This iteration supported MP3 and video streaming. It
also supported connecting to a QuickTime streaming server. Here, one of
the fundamental building blocks for the live streaming of audio-visual
data across the internet was laid. In December 1999, Apple launched
QuickTime 4.1, meaning Apple released two big updates this year. This
was a major update, allowing the processing of video files larger than 4
GB. The update introduced variable bitrate for Mp3 files, allowing
better quality files to be produced. In 1999, Apple also launched
iMovie, a video editing software aimed at consumers, not professional
filmmakers. This software radically simplified video editing by building
on the abstraction that the QuickTime framework created. Needless to
say, for videobloggers, iMovie enabled a more rapid and professional
looking production of video and was widely used.

QuickTime 5.0 was launched in 2001, which allowed MPEG 1 video playback
(for both Mac and Windows). Apple added Sorenson video 3 playback, Flash
4 playback and export, and had a new VR engine. By supporting real-time
rendering of effects and transitions in DV files, QuickTime 5.0 was the
first launch that seriously developed QuickTime’s potential as a video
*editing* software, and not just a media player. The elements of
technology for supporting videoblogging were therefore strengthening
into a comprehensive technical system. In 2002, Apple launched QuickTime
6.0, supporting MPEG 4 playback, import and export, as well as support
for Flash 5, JPEG 2000 and MPEG 2 playback. Apple also included support
for Instant On Streaming Playback, which would change the way video
content could be consumed online. Also launched, but not by Apple, was
the RSS 2.0 feed specification and many implementations of it were
supported on websites and blogs, enabling the syndication and
distribution of videoblogs. This was another key technology for
videoblogging.

Additional support for AAC/AMR codecs, which increased the quality of
compression for audio output, was introduced in June 2003, when Apple
released QuickTime 6.3. Apple also included the first support for mobile
formats, the 3gPP codec,[^04chapter3_21] which supported mobile video camera
formats from brands such as Nokia and Sony Ericsson. This allowed
seamless movement of files between mobile and computer, allowing not
only playback possibilities, but also more logical storage and archiving
of mobile video files.[^04chapter3_22] In October of the same year, Apple launched
the Pixlet codec, allowing QuickTime to process High Definition (HD)
video files. By December, QuickTime 6.5 was launched, reinforcing
Apple’s support for 3gPP (mobile), AMC (audio) and Apple lossless
format. Thus we can see that Apple yet again moved the bar in terms of
democratising its software, which was usable by professionals and
consumers, and laying the foundations for increased streaming services
across wireless networks. Indeed, 2003 was also the year Chris DeWolfe
and Tom Anderson launched Myspace, which, for a short period before
Facebook and Twitter, would become one of the largest social networks on
the internet, as well as one the first sites to promote video content.

In 2003, Apple released Final Cut Pro 4, a professional video-editing
software suite which included a package of additional applications,
*Compressor* for transcoding between video formats, *LiveType*,
*Soundtrack,* and *CinemaTools.* Apple also launched Final Cut Express,
a cheaper and slightly downgraded version of Final Cut Pro. Final Cut
Express became a useful tool for those within the Videoblogging
community who wanted to edit their videos but who either didn’t have the
technical expertise or financial ability to get to grips with Final Cut
Pro. Final Cut Express allowed more advanced editing than iMovie,
producing a more professional looking result and again found an
important user base in the videoblogging community.

The term ‘podcasting’ was coined by Ben Hammersley, a technology writer
for the Guardian, in 2004, when he ‘rhetorically asked what the emerging
practice of amateur online radio should be named: ‘Audioblogging?
Podcasting? Guerilla Media?’’[^04chapter3_23] Podcasting was the creation of

> A digital media file, or a series of such files, that is distributed
> over the internet using syndication feeds for playback on portable
> media players and personal computers. Like ‘radio’, the term can refer
> either to the content itself or to the method by which it is
> syndicated… The host or author of a podcast is often called a
> podcaster.[^04chapter3_24]

As such, podcasting can be seen as closely related to both blogging and
videoblogging (there also exists the term audio-blogging, which
indicates that audio files are regularly embedded in a users’ blog, much
like videos are embedded in the videoblogger’s videoblog). Sterne et al
argue that podcasting is a conflation of iPod and broadcasting and
divide podcasting into practice and product. They further observe that
podcasting continues to work through the division between producer and
consumer – that it is not merely an extension of blogging culture.[^04chapter3_25]

After the launch of YouTube, a number of competing video platforms were
launched in 2005. In April, Dailymotion was launched, a French video
sharing website founded by Benjamin Bejbaum and Olivier Poitrey. Other
examples of video platforms include Veoh (founded by Dmitry Shapiro in
September 2006), Vimeo (founded November 2004, VideoEgg (founded by
David Lerman, Matt Sanchez and Kevin Sladek in early 2005).[^04chapter3_26] In
July, News Corporation bought Myspace in a shocking \$580 million deal.
Since February 2005, Myspace users’ had the ability to embed YouTube
videos in their Myspace profiles and realizing the competitive threat to
the new MySpace Videos service, Myspace banned embedded YouTube videos
from its user profiles. MySpace users widely protested the ban,
prompting Myspace to lift the ban shortly thereafter. However, News
Corporation failed to capitalise on Myspace’s potential, and it was soon
overtaken by its rivals.

Apple launched QuickTime 7.0 on April 28th 2005. This upgrade introduced
the codec H264,[^04chapter3_27] which was to become the standard format for
audio-visual digital content across all of Apple’s mobile media devices
(including the iPhone, iPod touch, iPad, and Apple Watch). It would
later become the industry standard format for displaying audio-visual
content on the internet, but at the time it was widely derided as poorly
supported in contrast to the flash ‘.flv’ format. Ironically, in
QuickTime 7.3 Apple dropped support for the flash format altogether.
Apple also upgraded to iMovie HD, which included support for HDV (720p
and 1080i) and introduced a new feature called ‘Magic iMovie’ –
streamlining the video editing process by automatically inserting a
pre-selected video-transition between clips. The H.264 format was
important as it allowed high quality video at lower bitrates than other
standards. It was half the bitrate of MPEG-2, H.263 or MPEG-4 part 2.
It’s best known for being the video encoding standard for Blu-Ray discs
and was well-designed to support streaming video. It is also notable for
its ability to support 4K UHD video and in this sense was a very
forward-looking technology.

In 2009 the discourses around online practices shifted from
participation to consumerism. The focus on participation and involvement
that had dominated media discourse since 2005 gave way to studies
showing how much online content people were consuming, how many hours of
video were being watched on YouTube and so on. This shift is mirrored by
the development of QuickTime. After four years of few major updates,
QuickTime X launched. This was significant, moving QuickTime from being a
specialised tool to a social media oriented application. In this
upgrade, Apple introduced visual chapters and the ability to perform
more complex editing from within QuickTime itself. It also supported
screen capture, the ability to record the screen of the computer whilst
the user is performing other tasks, and support for capture of video and
audio streams. It increased GPU acceleration and improved live
streaming. This version of QuickTime, which had been completely
re-written in order to support 64-bit audio and video codecs, dropped
some of the earlier codecs. Perhaps most interestingly, however,
QuickTime now allowed direct sharing to YouTube, bypassing the previous
complex system of compression and codecs, essentially allowing anyone
with little previous knowledge of video formats to export video *in the
correct and optimised format* directly to YouTube. In other words, one
expert layer of knowledge about the export of audio-visual content via
QuickTime was abstracted away, transforming the process of creating,
uploading and sharing video to the internet. Video-sharing’s technical a
priori was now in place.

Gradually, corporations and industry started to see the potential profit
from online video distribution. For example, in February 2007, Netflix,
the online movie-rental service, which had been posting DVDs to
subscribers since 1994, introduced video-on-demand to its subscribers.
In December 2007, the BBC iPlayer was launched; a Flash based video
streaming service giving users online access to BBC programmes. The
service had been in ‘beta’ since the summer, and was criticised for only
working with the Windows XP operating system. As a publicly funded
public service broadcaster, it was very odd for the BBC to miss an
opportunity to develop the spirit of community and diversity represented
by the GNU/Linux and open web. It goes without saying that Microsoft at
the time represented a monopoly on user desktops. After a petition
signed by over 16,000 people, the government said the BBC would ensure
the iPlayer worked with other operating systems. In October, the BBC
entered a strategic relationship with Adobe, in order to provide
streaming across multiple platforms (Macintosh, Linux and Windows). This
relationship was ‘part of the BBC’s strategy to reinvent bbc.co.uk to
ensure that all its rich-media content is accessible to the widest
audience possible’.[^04chapter3_28] When the iPhone 3GS (the first in Apple’s
iPhone range capable of shooting video) was launched in 2009, the
possibility for short-form digital film went truly mainstream. The Apple
App Store opened in 2008, and brought with it a potentially massive
market for film editing apps.

Unfortunately, one cannot talk about online video without talking about
the elephant in the room, YouTube. Not only does YouTube dominate online
video consumption, but the desirability of its audience compels others
to chose the platform to upload their videos. Likewise, YouTube also
tends to dominate academic discussion of online video, now of course
naturalized to digital video. The way in which digital technologies have
a tendency to monopoly as platforms is an interesting research question
– but its oversized representation in academic discussion is something
this book aims to push back on. Nonetheless, to do justice to the
development of videoblogging, YouTube has to feature, if only
tangentially. With this in mind, I want to quickly sketch the technical
milieu that soon came to overwhelm and undermine grass roots
videoblogging.

YouTube grew at an incredible rate between 2006 and 2008, and in only a
few years the site completely dominated the online video sphere. In 2008
alone, YouTube received around ‘64 million unique visitors a month and
\[was\] the third most visited site in the United States after Google
and Yahoo’.[^04chapter3_29] There is no doubt that this growth led to many changes
to the site itself. In 2005, for example, it was still possible to
upload a video and watch it hover on the ‘recently uploaded’ tab for at
least an hour or so. This feature was later removed, as the stream of
uploaded videos started moving so quickly that it was impossible to keep
up. This has now been replaced with a ‘recently uploaded – recommended
for you’ feature, based on your viewing history, similar to Twitter’s
‘in case you missed it’ feature. By 2014, YouTube boasted an impressive
1 billion unique visitors a month, and by 2017 a staggering 3.25 billion
hours of video were watched on the site every month. YouTube might not
be the haven of user-generated content it once was, as Geert Lovink
reminds us, ‘YouTube’s slogan, ‘Broadcast Yourself’, is put into action
by less than 1 per cent of its users’.[^04chapter3_30] Rather, he argues, ‘in this
Long Tail age, we know that it’s mainly about “Broadcasting to
Yourself”’. In many ways, then, YouTube has developed and grown into a
platform which is ‘negotiating and navigating between community and
commerce’.[^04chapter3_31]

YouTube is often talked about in popular culture as if it is a library,
an archive or a laboratory, and sometimes as if it is a medium like
television. Although cultural contexts give the site different meanings,
from a strictly computer-science viewpoint, YouTube is nothing but a
database.[^04chapter3_32] This reflects Lovink’s comment from 2008 that ‘we no
longer watch films or TV, we watch databases’.[^04chapter3_33] Attempts have been
made to tackle the platform analytically, providing useful overviews of
the service, it’s users and cultural significance. These studies often
do so at the cost of much detailed investigation into the specifics of
the platform. Jean Burgess and Joshua Green’s important text on YouTube
gives an impressive snapshot of the platform. They create a typology of the
videos found on YouTube, from corporate advertising campaigns, via music
videos, fan videos and vlogging. This survey is incredibly valuable as
it gives us an indication of where the platform was at the time and how
much it has changed since.

In 2008, over half the videos on YouTube were user-generated, 40% of
which were vlogs.[^04chapter3_34] Vlogging was a relatively established practice
amongst the early adopters on YouTube. However, traditional content,
defined as ‘videos originally produced within the established media
industry’ ranked higher than the user-generated content in terms of
number of views and favourites. On the other hand, user-generated
content far outweighed the traditional when it came to most discussed
and most responded to, thus reinforcing the value of vlogging for a
sense of community.

Patricia Langeon the other hand, points out a number of what she calls (mis)conceptions
about YouTube. The first is that YouTube is a video sharing site. She
argues that in addition to sharing videos there, ‘for a subset of
participants, YouTube is an imagined community of people who share an
interest in video making or communicating through interactive
video’.[^04chapter3_35] As such, YouTube is arguably *more* than a video-sharing
site. The second (mis)conception is the desire for researchers to study
‘ordinary people’ on YouTube, arguing that ‘if you are posting videos on
YouTube, you are arguably no longer ordinary, if by ordinary we mean a
person who has no special interest in or connections to intensive
media-making’. Lange argues that the technical requirements, time and
effort it takes to post videos, coupled with the fact that only a small
percentage of registered YouTube user actually post videos at all, means
the idea of studying ‘ordinary users’ is itself flawed. Thirdly, Lange
argues that contrary to the fact that most users simply go to the site
to watch particular videos, YouTube is a community, populated by users
who invest in each other and each other’s content. As she argues, ‘the
suggestion here is not that all people on YouTube feel part of a
community or even part of a specific community or group of friends. The
contention is rather that not all people who watch videos on YouTube are
casual two-minute viewers of specific videos’.[^04chapter3_36]

>By January 2009, it was estimated that 100.9 million viewers watched 6.3
billion videos on YouTube.com (62.6 videos per viewer) for a 43 per cent
market share. In comparison, Fox Interactive Media ranked a distant
second in terms of videos viewed, with 552 million videos (3.7 per
cent). On a global scale, 77 per cent of the total US Internet audience
watched online video for an average of six hours in January 2009.[^04chapter3_37]

Towards the end of 2009, what we see is a shift in the way
social media use was being reported; whereas so far the focus had been
mainly on participation, and the way in which new participatory media
opened up far wider audience interaction, at the end of 2009, the focus
started drifting towards ‘engagement’, a euphemism for consumption. To
illustrate, in January 2009, YouTube announced a new partnership with
Apple, offering users ‘a dynamic, lean-back, 10-foot television viewing
experience through a streamlined interface’.[^04chapter3_38] This announcement
meant the integration of YouTube with Apple iTunes, allowing users to
watch YouTube videos directly on their televisions, further blurring the
distinction between online and offline content, as well as the
distinction between online and offline behaviour. YouTube’s expansion
into ‘offline’ media continued with the announcement, in April 2009, of
a partnership with Sony ‘to expand its library of movies and TV shows’.
The extent to which YouTube is an accepted part of the media landscape
is also reflected in the decision of the Library of Congress to create its
own YouTube channel. During spring 2009, the Library announced that it
would begin to upload millions of clips to YouTube.

Since 2010, online video moved in two directions. In terms of viewing
online video, increased bandwidth has meant a massive increase in
real-time streaming of either live or archived data. This has made
viewing content online easier, more readily available and, with services
such as Netflix, Hulu, BBC iPlayer Apple iTunes, and HBO Online,
bringing a much wider range of content to the user. Some of these
services, like the BBC iPlayer, are ‘free’ (or, in the UK at least,
funded by the TV licence), whereas Netflix and HBO online charges a
monthly subscription fee. Other services, such as the UK-based BlinkBox
(rebranded as TalkTalk TV Store in July 2016), charge users per episode,
series or film. On the other hand, sites such as YouTube allow its users
to upload videos up to 15 minutes long and files larger than 20GB.
Video-sharing also moved out of the browser and into mobile
applications, which are highly personal (also see Lovink on what he
calls ‘*totale Mobilmachung*’ of visual culture).[^04chapter3_39] Similarly, Nanna Verhoeff
argues that ‘screens are objects, technologies, apparatuses and machines
of vision, all at once’.[^04chapter3_40]

To complete this compressed history of digital video, more recently, in
September 2011, Snapchat was launched. Initially named Picaboo,
Snapchat originally allowed users to share images that would
self-destruct after a few seconds. The app has since introduced
video-sharing and ‘stories’ – where users can post updates throughout
the day. To increase the sense of immediacy, all images and videos
posted to the story are deleted after 24 hours, though later software
updates allowed the user to save their stories within the application,
or download onto their camera roll. In 2012, two new video processing
applications (apps) were also launched,[^04chapter3_41] and which also commodified
something akin to the videoblogging aesthetic. Vine, a short-lived but
much loved video sharing app, allowed the user to record 6 seconds of
video by tapping the screen (which operated as the viewfinder) and
another video processing app, Light, released only months before. Light
created short, stop-motion videos by recording one frame a second for
approximately ten seconds. Both Vine and light were great examples of
tools of interest to those fascinated with ‘light weight, ready to hand
video documentation practices that want to seriously engage with and
intersect the everyday’ in a way similar to that trail blazed by
videoblogs.[^04chapter3_42]

Meanwhile, QuickTime continued to be developed by Apple, and in March
2012, QuickTime 10.2 was launched, supporting more social sharing,
allowing users to share their videos instantly to either email, YouTube
or Facebook but also directly to devices, such as iPhone, iPod and Apple
TV. The history of QuickTime documents a codec that developed from a
very technically complex software package (media player and codec),
requiring expert knowledge of the requirements of formats and
compression, into an abstracted social media aware framework, allowing
the quick and easy processing of audio-visual data. In its last
iteration, QuickTime also made sharing data across the internet very
simple. What is interesting is that in the period between 2005 and 2009,
in which QuickTime was, by any means, a stable codec, with relatively
minor upgrades, the videoblogging community was at its most active. I
merely note that the relative stability of QuickTime might have
contributed to the emergence and relative success of videoblogging. A
lot of the discussions early on within the community circled around the
problem of negotiating a rapidly changing technological landscape and
QuickTime made this relatively easier. For the majority of this chapter
of the videoblogging ‘era’ one of the most important technologies used
by the community was actually relatively stable. The conditions of
possibility for the videoblogging practice rests partially upon the fact
that Apple slowed their QuickTime releases as they were in the process
of modernising their operating system and hardware.[^04chapter3_43]

In 2013, Instagram, an established photosharing site recently purchased
by Facebook, launched video as part of their service. This allowed up to
15 seconds of video to be recorded. The method of capturing video in
Vine and Instagram (tapping finger on viewfinder in Vine, and pressing
and releasing finger on record button in Instagram video) produced a
similar aesthetic. This created a comparable effect to the fast-edits of
early videoblogging. Whereas it could take the videoblogger a long time
to create this effect in software packages such as iMovie, Final Cut Pro
or QuickTime, here the process was automated and user friendly. In many
ways, then, the more recent applications and software packages that
handle online video, have taken the videoblogging practices, automated,
simplified and streamlined them, so that the videoblogging aesthetic is
now available at the click of a button.

Videoblogging remained a marginal practice for a long time, although
recent years have seen the success of a younger generation of
videobloggers who are creating global brands for themselves, see for
instance Michelle Phan, a beauty vlogger who has an impressive 6.7
million subscribers.[^04chapter3_44] Phan posts tutorials about makeup and posts
life advice to her followers. Another example is British vlogger Zoe
Elizabeth Sugg, better knows as Zoella, who has monetised her beauty and
lifestyle YouTube channel into a multi-million pound business.[^04chapter3_45]
Since becoming ‘internet famous’, she has written a book, launched her
own line of beauty products, started a WH Smiths book club and designed
a range of stationary for them. Her YouTube channel attracts over a
million views per episode, and she can charge up to £20k for
endorsements on her channel or Instagram page. Clearly, video online has
changed dramatically in just a decade.[^04chapter3_46]

One of the interesting things about the period 2004-2009 is the extent
to which the self-identity of the videoblogger and the platform
technologies were continually contested by the community. Even as the
technologies began to encode certain practices, the generally high
technical competence of the videobloggers meant that they could always
choose to reject or unpick a particular delegation of their practice.
This placed the videobloggers in an interesting position of power in
relation to the platform developers (who also often included the
videobloggers themselves). In effect this often meant that the
developers had to woo the videobloggers and thus enrol them into using
their systems by making the platform technologies themselves ‘looser’
and hence more customizable. This also meant that the ability for this
platform to create any sense of lock-in, or loyalty, was limited – which
also potentially lessened any commercialisation strategies by the
platform developers. This looser, open development method has resonance
with free and open source software, and it is certainly the case that
videobloggers had a relatively sophisticated understanding of, for
example, intellectual property rights. YouTube, on the other hand, with
its flash-based technologies and practices was swallowed by Google where
it developed into a much more mainstream short-video platform.[^04chapter3_47]
YouTube is also more clearly structured around a traditional notion of
what video ‘should be’ in as much as it is structured heavily around
‘hits’, internet memes, popularity and ‘likes’. YouTube tried to
incentivise their users in other ways. The YouTube revenue-sharing
program, which was launched in 2007, paid money for people to distribute
their content on the platform. ‘Once a creator signed, Google would load
up the channel with advertising, take a 45 percent cut of the resulting
revenue, and hand over the rest. For many YouTube creators the money was
an incentive to keep going but wasn’t enough to live on. They still had
to hustle’.[^04chapter3_48] But this point here is no doubt that the sphere of
video as a grass roots experimental community was mostly over.

Today we tend to take for granted these earlier technical systems,
particularly important issues like the slow refinement of the video
codecs that made online video possible at all. Nonetheless, as I have
tried to show in this chapter, a number of technical preconditions, none
of them easy, had to be resolved before they could be combined to create
the beginnings of a video platform. A platform is a standardised
technical architecture that simplifies, standardises and systematises a
constellation of technologies. Once this is done, the drive to
monopolise the platform takes place, and hence aggregate a massive user
base which can then be monetised, for example through advertising. The
classic instance of this process is, of course, YouTube which seeks very
aggressively to preserve its quasi-monopoly over social media and hence
to reap the profits from almost complete control of video online.

[^04chapter3_1]: See for instance Sherry Turkle, Life On the Screen. Identity in
    the Age of the Internet; Kennedy, ‘Beyond Anonymity’; Rheingold,
    *Virtual Communities*; Jenkins, Convergence Culture. Where Old and
    New Media Collide; Castells, The Information Age. Vol. I: The Rise
    Of The Network Society, Castells, The Information Age. Vol. II: The
    Power Of Identity; Noble, Safiya Umoja. *Algorithms of Oppression:
    How search engines reinforce racism*. NYU Press, 2018; Abbate,
    Janet. *Recoding gender: Women's changing participation in
    computing*. MIT Press, 2012; Nagle, Angela. *Kill all normies:
    Online culture wars from 4chan and Tumblr to Trump and the
    alt-right*. John Hunt Publishing, 2017; Turkle, Sherry. *Alone
    together: Why we expect more from technology and less from each
    other*. Hachette UK, 2017; Pariser, Eli. *The filter bubble: What
    the Internet is hiding from you*. Penguin UK, 2011; Taylor,
    Astra. *The people's platform: Taking back power and culture in the
    digital age*. Metropolitan books, 2014; Carr, Nicholas. *The
    shallows: What the Internet is doing to our brains*. WW Norton &
    Company, 2011.

[^04chapter3_2]: For instance, see Kirschenbaum, ‘Extreme Inscription: The
    Grammatology of the Hard Drive’; Berry, *The Philosophy of Software:
    Code and Mediation in the Digital Age*; Alexander R. Galloway,
    *Protocol: How Control Exists After Decentralization*; Matthew
    Fuller, *Software Studies: A Lexicon*, Cambridge: MIT Press: 2008;
    Ian Bogost *Alien Phenomenology, or What It’s Like to Be a Thing*,
    Minneapolis: University of Minnesota Press, 2012.

[^04chapter3_3]: Ganaele Langlois, Fenwick McKelvey, Greg Elmer, and Kenneth
    Werbin. ‘Mapping Commercial Web 2.0 Worlds: Towards a New Critical
    Ontogenesis’. *Fibreculture* 14 (2009): p. 1-14.

[^04chapter3_4]: Janet Abbate, *Inventing the Internet*, Cambridge, MA: MIT press,
    2000, see also John Naughton, *A Brief History of the Future*,
    London: Phoenix Press, 1999, Manuel Castells, *The Information Age.
    Vol. I: The Rise Of The Network Society*, Oxford/Cambridge:
    Blackwell, 1996, Manuel Castells, *The Information Age. Vol. II: The
    Power Of Identity,* Oxford/Cambridge: Blackwell, 2000. Castells, M.
    (2001) *The Internet Galaxy*, Oxford/Cambridge: Blackwell.

[^04chapter3_5]: Martin Campbell-Kelly and Daniel D. Garcia-Swartz, ‘The history of
    the internet: the missing narratives’. *Journal of Information
    Technology*, 28.1 (2013), p. 18.

[^04chapter3_6]: Abbate, *Inventing the Internet*, p. 214. See also Ted Nelson,
    Branching presentational systems-Hypermedia, *Dream Machines*, 1974,
    pp. 44-45 and Noah Wardrip-Fruin and Nick Montfort, *The
    NewMediaReader*, Cambridge, MA: MIT Press, 2003.

[^04chapter3_7]: Tim Berners-Lee, The World Wide Web: A very short personal
    history, 1998,
    http://www.w3.org/People/Berners-Lee/ShortHistory.html, accessed 11
    June 2014.

[^04chapter3_8]: Campbell-Kelly and Garcia-Swartz, ‘The history of the internet:
    the missing narratives’, p. 26.

[^04chapter3_9]: Rheingold, *The virtual community*, see also Fred Turner, *From
    counterculture to cyberculture: Stewart Brand, the Whole Earth
    Network, and the rise of digital utopianism*. University of Chicago
    Press, 2010.

[^04chapter3_10]: Vint Cerf et al, Brief History of the Internet,
    *InternetSociety.org*,
    http://www.internetsociety.org/internet/what-internet/history-internet/brief-
    history-internet\#History, accessed 24 June 2014.

[^04chapter3_11]: John Perry Barlow, A Cyberspace Independence Declaration.

[^04chapter3_12]: Aimee Hope Morrison, An impossible future: John Perry Barlow’s
    ‘Declaration of the Independence of Cyberspace’, *New Media &
    Society*, 11.1-2, (2009) pp. 53-71.

[^04chapter3_13]: Marshall T. Poe, *A History of Communications: Media and Society
    from the Evolution of Speech to the Internet*, Cambridge: Cambridge
    University Press, 2011, p 225.

[^04chapter3_14]: Langlois et al, ‘Mapping Commercial Web 2.0 Worlds: Towards a New
    Critical Ontogenesis’.

[^04chapter3_15]: This was detailed by Guy Kawasaki in relation to the mailing
    lists he used to direct the early adopter community in particular
    directions or to gain feedback on products.

[^04chapter3_16]: See Jonathan Sterne. *MP3: The meaning of a format*. Duke
    University Press, 2012.

[^04chapter3_17]: Ursula Franklin, *The Real World of Technology*, p. 15.

[^04chapter3_18]: Andreas Haugstrup Pedersen, Cheryl Colan, Enric Teller and
    Raymond M. Kristiansen all explicitly mentioned it, but looking
    through their videoblogs, I found that a much larger number relied
    on this particular codec.

[^04chapter3_19]: Sean Cubitt, ‘Codecs and Capability’, in Geert Lovink and Sabine
    Niederer (eds) *Video Vortex Reader. Responses to YouTube*,
    Amsterdam: Institute for Networked Cultures, 2008, p. 46.

[^04chapter3_20]: Manovich, *The Language of New Media*, p. 313.

[^04chapter3_21]: 3gPP was the industry’s first mainstream solution to support the
    third generation partnership project standard, which allowed a
    foundation for the delivery and playback of rich multimedia content
    over wireless networks.

[^04chapter3_22]: These video files were very small, with very low resolution, so
    were perfect for device-to-device sharing, but not much else.
    Nonetheless, the collapse in formats between computation and
    telephony was an important anticipation of the later moves by Apple
    in mobile technology.

[^04chapter3_23]: Jonathan Sterne, Jeremy Morris, Michael Brendan Baker, and Ariana
    Moscote, ‘The Politics of Podcasting’, *Fibreculture*, issue 13
    (2008).

[^04chapter3_24]: Jonathan Sterne, *MP3: The meaning of a format*.

[^04chapter3_25]: It is interesting to note the explosion of podcasting media in
    2017, with podcasts such as *RadioLab, Radiotopia*, *Invisible 99*,
    *My Dad Wrote Porno* and many others getting a mass listenership.
    However, its political economy remains shaky.

[^04chapter3_26]: There are too many to list here, but a few important ones are
    Archive.org, blip.tv. Dailymotion, Facebook, Funny Or Die, GodTube,
    Hulu, LiveLeak, Mefeedia, Openfilm, and Photobucket.

[^04chapter3_27]: H264 is a video-compression format. It is particularly good
    because it is able to produce high quality video in relatively low
    bitrates.

[^04chapter3_28]: BBC Press office, ‘BBC enters strategic relationship with Adobe
    to enhance BBC iPlayer and bbc.co.uk’, *BBC Press Office*, 2007,
    http://www.bbc.co.uk/pressoffice/pressreleases/stories/2007/10\_october/16/adobe.shtml,
    accessed 13 June 2014.

[^04chapter3_29]: Matthew Mitchem, ‘Video Social: Complex Parasitical Media’, in
    Geert Lovink and Sabine Niederer (eds) *Video Vortex Reader.
    Responses to YouTube*, Amsterdam: Institute for Networked Cultures,
    2008, p278.

[^04chapter3_30]: Geert Lovink ‘The Art of Watching Databases’, in Geert Lovink and
    Sabine Niederer (eds) *Video Vortex Reader. Responses to YouTube*,
    Amsterdam: Institute for Networked Cultures, 2008, p. 11.

[^04chapter3_31]: Pelle Snickars and Patrick Vonderau, *The YouTube Reader*,
    Stockholm: Mediehistorisk arkiv, 2009, p.11.

[^04chapter3_32]: Snickars and Vonderau, *The YouTube Reader,* p. 13.

[^04chapter3_33]: Lovink, ‘The Art of Watching Databases’.

[^04chapter3_34]: Burgess and Green, *YouTube,* p. 43.

[^04chapter3_35]: Patricia Lange, ‘(Mis)Conceptions about YouTube’, in Geert Lovink
    and Sabine Niederer (eds) *Video Vortex Reader. Responses to
    YouTube*, Amsterdam: Institute for Networked Cultures, 2008, p.88.

[^04chapter3_36]: Lange, ‘(Mis)Conceptions about YouTube’, p. 96.

[^04chapter3_37]: William Uricchio, ‘The Future of a Medium Once Known as
    Television’, in Pelle Snickars and Patrick Vanderau (eds) *The
    YouTube Reader*, Mediehistorisk arkiv, 2009, p. 27.

[^04chapter3_38]: Snickars and Vonderau, *The YouTube Reader*, p. 11.

[^04chapter3_39]: Geert Lovink, ‘Engage in Destiny Design: Online Video beyond
    Hypergrowth’, in Geert Lovink and Racheal Somers Miles, (Eds) *Video
    Vortex Reader II: Moving Images Beyond YouTube*, Amsterdam:
    Institute for Networked Cultures, 2011.

[^04chapter3_40]: Nanna Verhoeff, *Mobile screens: The visual regime of
    navigation,* Amsterdam University Press, 2012, p. 16.

[^04chapter3_41]: Vine amassed over 40 million users in its first year although
    there is some contention about this figure, as well as a question to
    be raised about how many of those are active users.

[^04chapter3_42]: Adrian Miles, ‘Vine and Light (a poetics of the sublime
    ordinary)’, 29 Janary 2013 from
    http://vogmae.net.au/vlog/2013/01/vine-and-lightt-a-poetics-
    of-the-sublime-ordinary/.

[^04chapter3_43]: Here I refer to their paradigm-shifting move from Power PC to
    Intel, a process first made public at the World Wide Developer
    Conference in 2005. The process was completed in August 2009, with
    the release of the ‘Snow Leopard’ upgrade to the Mac operating
    system.

[^04chapter3_44]: https://www.youtube.com/user/MichellePhan.

[^04chapter3_45]: https://www.youtube.com/user/zoella280390/.

[^04chapter3_46]: YouTube is also host to a number of political and activist video
    makers, allowing small grassroots organisations like Novara media to
    flourish. Novara media tell stories about racism and climate change
    with the goal of ‘elevating critical perspectives’ they claim you
    are unlikely to encounter in the mainstream media. Although there is
    no space to explore this in more detail here, it is worth mentioning
    that YouTube, in it’s apparently neutrality regarding political
    affiliation, also plays host to a range of conservative and
    Alt-right channels, like the Canadian political activist Lauren
    Southern, who has become both popular and influential.

[^04chapter3_47]: Of course, ‘open’ platforms also have the possibility, and
    frequently attempt, to monetize their services, see for instance the
    success of Ubuntu and the Android operating systems.

[^04chapter3_48]: Felix Gillette, ‘Hollywood's Big-Money YouTube Hit Factory’,
    Bloomberg Businessweek, accessed 08 September 2014 from
    http://www.businessweek.com/articles/2014-08-28/youtube-hollywoods-hit-factory-for-teen-entertainment.
